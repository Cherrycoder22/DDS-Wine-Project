---
title: "Wine Analysis"
output: html_document
date: "2024-12-15"
---
```{r setup, include=FALSE}
library(caret)
library(randomForest)
#Read Datasets
wine_test <-read.csv("/Users/cherokeecarr/Desktop/Wine Test Set.csv")
print(wine_test)
wine_train <- read.csv("/Users/cherokeecarr/Desktop/Wine Train.csv")
print(wine_train)
# Combining datasets vertically (adding rows)
missing_columns <- setdiff(colnames(wine_train), colnames(wine_test))
wine_test[missing_columns] <- NA
colnames(wine_test) <- colnames(wine_train)


Vino <- rbind(wine_train, wine_test)

Vino <- na.omit(Vino)
# Set a random seed for reproducibility
set.seed(123)

# Get the number of rows in your dataset
n <- nrow(Vino_clean)

# Create an index to sample 70% of the data for training
train_index <- sample(1:n, size = 0.7 * n)

# Split the dataset into training and testing sets
wine_train <- Vino_clean[train_index, ]
wine_test <- Vino_clean[-train_index, ]

# Convert the 'quality' variable to a factor
wine_train$quality <- factor(wine_train$quality)
wine_test$quality <- factor(wine_test$quality, levels = levels(wine_train$quality))

# Train the Random Forest Model
rf_model <- randomForest(quality ~ density + pH + fixed.acidity + volatile.acidity +
                           residual.sugar + citric.acid + sulphates + alcohol,
                         data = Vino)

# Make predictions using the Random Forest model
rf_predictions <- predict(rf_model, newdata = wine_test)
print(rf_predictions)

# Ensure that quality column in wine_test has the same factor levels as in training data
wine_train$quality <- factor(wine_train$quality, levels = levels(Vino$quality))

# Make predictions using the Linear Model
lm_predictions <- predict(lm_model, newdata = wine_test)
print(lm_predictions)

# Calculate MAE for both models
lm_mae <- mean(abs(lm_predictions - wine_test$quality))
cat("Linear Model MAE:", lm_mae, "\n")

rf_mae <- mean(abs(rf_predictions - wine_test$quality))
cat("Random Forest MAE:", rf_mae, "\n")

lm_model <- lm(alcohol ~ density + pH  + fixed.acidity + volatile.acidity +residual.sugar, data = wine_train)
print(lm_model)

# Make predictions on the test set (wine_test should be the actual test data)
lm_predictions <- predict(lm_model, newdata = wine_test)
rf_predictions <- predict(rf_model, newdata = wine_test)

# Calculate MAE for Linear Regression
lm_mae <- mean(abs(lm_predictions - wine_test$alcohol))
cat("Linear Regression MAE:", lm_mae, "\n")

# Calculate MAE for Random Forest
rf_mae <- mean(abs(rf_predictions - wine_test$alcohol))
cat("Random Forest MAE:", rf_mae, "\n")

# Compare which model has a lower MAE
if (lm_mae < rf_mae) {
  cat("Linear Regression performs better with a lower MAE:", lm_mae, "\n")
} else {
  cat("Random Forest performs better with a lower MAE:", rf_mae, "\n")
}

```

Analysis A, we were tasked to build a predictive model with the lowest possible MAE. I built two different models to compare. One, with as many relevant predictors as possible and the other as a simplified version. One comparing the two, lm_mae has the lower MAE with .446. The key to a lower MAE is to assure the predictors are actually building the model and not being used as filler. As well as making a simple model with as much predictable information as possible.




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(e1071)  # For naiveBayes
library(caret)
wine_test <-read.csv("/Users/cherokeecarr/Desktop/Wine Test Set.csv")
print(wine_test)
wine_train <- read.csv("/Users/cherokeecarr/Desktop/Wine Train.csv")
print(wine_train)


quality_9_wines <- subset(wine_train, quality == 9)

# Check the first few rows of the filtered dataset
head(quality_9_wines)

quality_8_wines <- subset(wine_train, quality == 8)
print(quality_8_wines)

```

## R Markdown

Analysis B, we were tasked to find the key factors in making high-quality wine. To start researching them, we decided to see what factors influence the quality 8 and 9 wines. 
After seeing those determinants, we decided to create a prediction on those models, coded below.

The strongest key factors were density, alchohol content, sugar level, fixed acidity, and volatile acidity. To help build model, we also included ph and citric acid even though they are not the strongest predictors. 

```{r}
library(caret)       # For confusionMatrix
library(e1071)       # For Naive Bayes

# Load the datasets
wine_test <- read.csv("/Users/cherokeecarr/Desktop/Wine Test Set.csv")
wine_train <- read.csv("/Users/cherokeecarr/Desktop/Wine Train.csv")

# Set a random seed for reproducibility
set.seed(123)

# Get the number of rows in your dataset
n <- nrow(Vino_clean)

# Create an index to sample 70% of the data for training
train_index <- sample(1:n, size = 0.7 * n)

# Split the dataset into training and testing sets
wine_train <- Vino_clean[train_index, ]
wine_test <- Vino_clean[-train_index, ]

# Convert the 'quality' variable to a factor
wine_train$quality <- factor(wine_train$quality)
wine_test$quality <- factor(wine_test$quality, levels = levels(wine_train$quality))

# Train the Naive Bayes model
nb_model <- naiveBayes(quality ~ density + pH + chlorides + fixed.acidity + volatile.acidity +
                         residual.sugar + citric.acid + sulphates + alcohol, data = wine_train)

# Print the Naive Bayes model summary
print(nb_model)

# Make predictions on the test set
predictions <- predict(nb_model, newdata = wine_test)

# Ensure the predicted values have the same levels as 'quality' in the training set
predictions <- factor(predictions, levels = levels(wine_train$quality))

# Compute the confusion matrix
confusion_matrix <- confusionMatrix(predictions, wine_test$quality)

# Print the confusion matrix
print(confusion_matrix)
```
```{r}
# Load necessary libraries
library(ggplot2)

# List of features to plot against 'quality'
factors <- c("density", "pH", "chlorides", "fixed.acidity", 
             "volatile.acidity", "residual.sugar", "citric.acid", 
             "sulphates", "alcohol")

# Loop over the factors and create scatterplots
for (factor in factors) {
  p <- ggplot(Vino_clean, aes_string(x = factor, y = "quality")) +
    geom_point() +
    labs(title = paste("Quality vs", factor), x = factor, y = "Quality") +
    theme_minimal()
  print(p)
}

```

